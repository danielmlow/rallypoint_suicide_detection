{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "authors: Noah Jones and Daniel Low\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPWy46c2m4e1"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q lightgbm==3.3.3\n",
    "# !pip install -q contractions==0.1.73\n",
    "# !pip install --user -U nltk==3.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "GsBEsViJOmMz",
    "outputId": "69c26e90-5e01-4942-e6c5-cb026f8029c1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import re\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import clone\n",
    "\n",
    "import contractions\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "int_bKwcnfKU"
   },
   "source": [
    "## Load Datasets and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.options.display.width = 0\n",
    "\n",
    "\n",
    "on_colab = False\n",
    "\n",
    "if on_colab:\n",
    "    from google.colab import drive\n",
    "    project_name = 'project_name'\n",
    "    drive.mount('/content/drive')\n",
    "    input_dir = '/content/drive/MyDrive/datum/rallypoint_suicide_detection/data/input/'\n",
    "    output_dir = '/content/drive/MyDrive/datum/rallypoint_suicide_detection/data/output/'\n",
    "else:\n",
    "    input_dir = './data/input/final_datasets/'\n",
    "    output_dir = './data/output/performance/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv(input_dir+'train.csv', index_col=0)\n",
    "val = pd.read_csv(input_dir+'val.csv', index_col=0)\n",
    "test = pd.read_csv(input_dir+'test.csv', index_col=0)\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "# We'll use CV for hyperparameter tuning, so we'll concatenate the train and val data\n",
    "train = train.append(val).reset_index(drop=True)\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_train_text = train['content']\n",
    "X_train_metadata = train[['type_tag_content','contact_size','reputation','type']]\n",
    "y_train = train['label'].values\n",
    "\n",
    "X_test_text = test['content']\n",
    "X_test_metadata = test[['type_tag_content','contact_size','reputation','type']]\n",
    "y_test = test['label'].values\n",
    "\n",
    "print(X_train_text.shape, X_train_metadata.shape, y_train.shape, X_test_text.shape, X_test_metadata.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total = 6478+692+1279\n",
    "1279/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED_VALUE = 10\n",
    "np.random.seed(SEED_VALUE)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False, random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import metrics_report # local script\n",
    "from sklearn import metrics\n",
    "def save_results_df(pipeline_gridsearch, X_train, y_train, X_test, y_test, model_name, output_dir= './', ts = None, results = {}):\n",
    "    \n",
    "    best_params = {}\n",
    "    for k,v in pipeline_gridsearch.best_params_.items():\n",
    "        best_params['estimator__'+k] = v\n",
    "\n",
    "    pipeline_gridsearch.set_params(**best_params)\n",
    "    print('training with best params...')\n",
    "    pipeline_gridsearch.fit(X_train, y_train)\n",
    "    print('done. evaluating on test set')\n",
    "    y_pred_proba = pipeline_gridsearch.predict_proba(X_test)\n",
    "\n",
    "    y_pred_proba_1 = y_pred_proba[:,1]\n",
    "    y_pred = [np.argmax(n) for n in y_pred_proba]\n",
    "    clf_report_sklearn = metrics.classification_report(y_test,y_pred, output_dict=False) #evaluate #different than the output of cross_validate() above.\n",
    "    cm_df_meaning, cm_df, cm_df_norm = metrics_report.cm(y_test, y_pred, output_dir, model_name, ts, save=True)\n",
    "    clf_report = metrics_report.classification_report(y_test,y_pred,y_pred_proba_1, output_dir, model_name, ts)\n",
    "    # scores = cross_validate(pipe, X, y, scoring=['f1','precision', 'recall'], cv=cv, return_train_score=False) #train and evaluate    \n",
    "    results[model_name] = {\n",
    "        'clf_report': clf_report,\n",
    "        'cm_df_meaning': cm_df_meaning,\n",
    "        'cm_df': cm_df,\n",
    "        'cm_df_norm': cm_df_norm,\n",
    "        'clf_report_sklearn': clf_report_sklearn\n",
    "\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(string):\n",
    "    string = string.replace('|body|',\"\")\n",
    "    string = re.sub(r\"http\\S+\", \"\", string)\n",
    "    string = re.sub(r\"www+\", \"\", string)\n",
    "    #fix contractions\n",
    "    string = contractions.fix(string,slang=False)\n",
    "    return string\n",
    "\n",
    "def custom_tokenizer(string):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(string)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED_VALUE = 10\n",
    "np.random.seed(SEED_VALUE)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False, random_state=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "toy = False\n",
    "\n",
    "if toy:\n",
    "    print('WARNING, running toy version')\n",
    "    param_grid = {\n",
    "       'vectorizer__max_features': [2000, None],\n",
    "        'model__penalty': ['l1', 'l2'],\n",
    "    }\n",
    "else:\n",
    "    param_grid = {\n",
    "        'vectorizer__max_features': [256, 2048, None],\n",
    "        'model__C': [0.1, 0.3, 0.6, 1],\n",
    "        'model__penalty': ['l1', 'l2'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'LogReg'\n",
    "\n",
    "output_dir\n",
    "output_dir_i = output_dir+model_name+'/'\n",
    "os.makedirs(output_dir_i,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "text_features = 'content'\n",
    "\n",
    "ts_i = datetime.datetime.utcnow().strftime('%y-%m-%dT%H-%M-%S')\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', binary=False,\n",
    "                 decode_error='strict',\n",
    "                 encoding='utf-8', input='content',\n",
    "                 lowercase=True, max_df=0.8, max_features=None,\n",
    "                 min_df=3, ngram_range=(1,2), norm='l2',\n",
    "                 preprocessor=preprocess, smooth_idf=True,\n",
    "                 stop_words=stopwords.words('english'), strip_accents='unicode',\n",
    "                 sublinear_tf=True,\n",
    "                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                 tokenizer=custom_tokenizer, use_idf=True,\n",
    "                 vocabulary=None)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# model = LogisticRegression(class_weight=\"balanced\", solver='liblinear')\n",
    "\n",
    "# Or just do this with the training set.\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "t_clf = imb_Pipeline([\n",
    "     ('vectorizer', vectorizer),\n",
    "         ('balancer', RandomOverSampler(random_state=SEED_VALUE)), # Doing this after TFIDF to not bias TFIDF weights\n",
    "     ('lgbm', model), \n",
    "    ])\n",
    "              \n",
    "# see all parameters: https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "# https://datascience.stackexchange.com/questions/108233/recommendations-for-tuning-xgboost-hyperparams\n",
    "\n",
    "# get cross validation split indexes\n",
    "iterable_train_val_indexes = []\n",
    "for train_i, val_i in kf.split(X_train_text):\n",
    "    iterable_train_val_indexes.append((train_i,val_i))\n",
    "\n",
    "text_grid_search = GridSearchCV(t_clf, param_grid, cv=iterable_train_val_indexes, scoring=[\"f1\"],refit=\"f1\", n_jobs=-1)\n",
    "text_grid_search.fit(X_train_text,y_train)\n",
    "\n",
    "\n",
    "print(text_grid_search.best_score_, text_grid_search.best_params_)\n",
    "\n",
    "# need to add estimator to parameter names \n",
    "\n",
    "# retrain with best params and evaluate on test set\n",
    "results = save_results_df(text_grid_search,X_train_text,y_train,X_test_text,y_test,\n",
    "                          model_name='logreg_text',\n",
    "                         output_dir=output_dir_i, ts = ts_i)\n",
    "\n",
    "for k, v in results.get('logreg_text').items():\n",
    "    print(k) \n",
    "    display(v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(text_grid_search.best_score_, text_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text + Metadata model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "ts_i = datetime.datetime.utcnow().strftime('%y-%m-%dT%H-%M-%S')\n",
    "\n",
    "numeric_features = ['contact_size','reputation','type']\n",
    "text_features = 'type_tag_content'\n",
    "\n",
    "# get cross validation split indexes\n",
    "iterable_train_val_indexes = []\n",
    "for train_i, val_i in kf.split(X_train_metadata):\n",
    "    iterable_train_val_indexes.append((train_i,val_i))\n",
    "    \n",
    "# Define pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "text_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='word', binary=False,\n",
    "                 decode_error='strict',\n",
    "                 encoding='utf-8', input='content',\n",
    "                 lowercase=True, max_df=0.8, max_features=20000,\n",
    "                 min_df=3, ngram_range=(1, 2), norm='l2',\n",
    "                 preprocessor=preprocess, smooth_idf=True,\n",
    "                 stop_words=stopwords.words('english'), strip_accents='unicode',\n",
    "                 sublinear_tf=True,\n",
    "                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                 tokenizer=custom_tokenizer, use_idf=True,\n",
    "                 vocabulary=None))])\n",
    "    \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('text', text_transformer, text_features)])\n",
    "\n",
    "\n",
    "model = LogisticRegression(class_weight=\"balanced\", solver='liblinear')\n",
    "\n",
    "\n",
    "mnt_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "         ('balancer', RandomOverSampler(random_state=SEED_VALUE)), # Doing this after TFIDF to not bias TFIDF weights\n",
    "\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "meta_num_text_grid_search = GridSearchCV(mnt_clf, param_grid, cv=iterable_train_val_indexes, scoring=[\"f1\"],refit=\"f1\", n_jobs=-1)\n",
    "meta_num_text_grid_search.fit(X_train_metadata,y_train)\n",
    "\n",
    "# need to add estimator to parameter names \n",
    "best_params = {}\n",
    "for k,v in meta_num_text_grid_search.best_params_.items():\n",
    "    best_params['estimator__'+k] = v\n",
    "\n",
    "\n",
    "# retrain with best params and evaluate on test set\n",
    "\n",
    "results = save_results_df(meta_num_text_grid_search,X_train_metadata,y_train,X_test_metadata,y_test,\n",
    "                          model_name='logreg_metadata',\n",
    "                         output_dir=output_dir_i, ts = ts_i)\n",
    "\n",
    "for k, v in results.get('logreg_metadata').items():\n",
    "    print(k) \n",
    "    display(v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_num_text_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnt_clf.fit(X_train_metadata,y_train)\n",
    "feature_names = mnt_clf.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "feature_names.shape #35 000+"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter Tuning of RP Models (tfidf, roberta, xlnet)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a76e472a5b7307be835d54f812a2629e79e37f69021d0ba9fc90fa7abdd826f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
